{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time, pickle\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1580195 entries, 0 to 1599998\n",
      "Data columns (total 3 columns):\n",
      "Unnamed: 0    1580195 non-null int64\n",
      "target        1580195 non-null int64\n",
      "text          1580195 non-null object\n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 48.2+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>upset updat facebook text might result school ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>dive mani time ball manag save rest bound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>whole bodi feel itchi like fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>behav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>whole crew</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  target                                               text\n",
       "0           0       0  upset updat facebook text might result school ...\n",
       "1           1       0          dive mani time ball manag save rest bound\n",
       "2           2       0                    whole bodi feel itchi like fire\n",
       "3           3       0                                              behav\n",
       "4           4       0                                         whole crew"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"processed_data.csv\")\n",
    "\n",
    "df.dropna(inplace=True); df\n",
    "df.info()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['text']\n",
    "y = df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "607258        realli wish london harsh realiti raini belfast\n",
       "384704                                       biggest headach\n",
       "102166     still sick soooooo much catch back school ahhh...\n",
       "757323                  longer fixtur visit good luck school\n",
       "1506152    much famili weekend realli time tweet better m...\n",
       "1273621                         well thing come play sammich\n",
       "1280392                   http paolovitolo click click click\n",
       "182044                              spent like half movi cri\n",
       "1471446                                          gonna think\n",
       "1119032                                    hyster magic ebal\n",
       "1505333                          watch show pretti good like\n",
       "372099                                                 raini\n",
       "258244     grey garden movi suck life invest enough time ...\n",
       "269811     know vinyl search high massiveb site say quot ...\n",
       "885288     like quot caricatur quot go follow culinari tr...\n",
       "1263674                                                 like\n",
       "654664                    still hurt ryan hug hard your mean\n",
       "679519                      wanna make mini pizza pizza sauc\n",
       "605348                                                 worst\n",
       "744230                                 wish could talk daddi\n",
       "1512719                                                 amaz\n",
       "400526          http twitpic hereeee long line blaaaaahhhhhh\n",
       "1587998    hindupm bluntli tell allow terror india stori ...\n",
       "1004789                    like laugh good time follow simpl\n",
       "66921                                         head hommmmeee\n",
       "1175481    cell verizon modem work help work use vast vis...\n",
       "1137075                   actual suppos lazi make drive like\n",
       "604868     evil monkey would good stick want cupboard cra...\n",
       "1548520                                   perez suspend zach\n",
       "630103            anim writer accur like went foot stop take\n",
       "                                 ...                        \n",
       "1060749                           oohh vote nicki shall vote\n",
       "686425                                 morn bore realli good\n",
       "415059                                             glad okay\n",
       "263876             say stop blog think close blog http plurk\n",
       "1460708                             aeolian block photo soon\n",
       "777373        forgot umbrella somewher drench rain feel cold\n",
       "621273                     went wamu left purs wanna shoppin\n",
       "965900     finchi sorri repli earlier twitter flood tri l...\n",
       "1570762    great still work fact know procrastin twitter ...\n",
       "299871            wharf wharf shoot gone wknd sign last move\n",
       "1153837    #sai mountain forest savannah desert tropic be...\n",
       "1198014                     oooo like jammin haha play twice\n",
       "871591                                     fine littl better\n",
       "297266                                       fail scienc tak\n",
       "1056643          go differ week stay tune thank everyon love\n",
       "827737                                     spam hale twitter\n",
       "1114224                               gratz soon come achiev\n",
       "185143     sure meant exam studi break someon someth soci...\n",
       "1549345                                      food today back\n",
       "991843                          today think anyth wash cloth\n",
       "948000                                   honestli amaz thank\n",
       "1242336                                    wait upgrad today\n",
       "200409                                     stupid trash woke\n",
       "1259309    train upper hutt train year lot find well vode...\n",
       "1255903    http twitpic fauf beati love come chile someda...\n",
       "1505625                                 hahaa well time haha\n",
       "1473560                                            know feel\n",
       "1084489         well never beatl beatlemaina thought younger\n",
       "927482                                       make smile lmao\n",
       "345248     dozen student still miss cadet colleg kidnap #...\n",
       "Name: text, Length: 1422175, dtype: object"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7627072522465511\n",
      "Time taken : 44  seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer(decode_error='ignore', ngram_range=(1,1), strip_accents='unicode')),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('cls', LogisticRegression(random_state=0, solver='liblinear'))\n",
    "]) \n",
    "\n",
    "# Train model\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Find predicted values\n",
    "y_predicted = pipeline.predict(X_test)\n",
    "\n",
    "# Find the test set accuracy score\n",
    "print (pipeline.score(X_test, y_test))\n",
    "\n",
    "end = time.time()\n",
    "exe_time = end - start\n",
    "print ('Time taken :',round(exe_time),' seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.501664\n",
       "4    0.498336\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_accuracy = y_test.value_counts() / len(y_test)\n",
    "base_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[59109, 20164],\n",
       "       [17333, 61414]], dtype=int64)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_predicted, labels=[0,4])\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted 0</th>\n",
       "      <th>predicted 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>59109</td>\n",
       "      <td>20164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17333</td>\n",
       "      <td>61414</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   predicted 0  predicted 4\n",
       "0        59109        20164\n",
       "4        17333        61414"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm_df = pd.DataFrame(cm, index=[0,4],\n",
    "                     columns=['predicted 0', 'predicted 4'])\n",
    "cm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['depression_model.pkl']"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(pipeline, 'depression_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "detail = \"sad\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['sad']"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "import re\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "def remove_pattern(input_txt, pattern):\n",
    "    r = re.findall(pattern, input_txt)\n",
    "    print(r)\n",
    "    for i in r:\n",
    "        input_txt = re.sub(i, '', input_txt)\n",
    "        \n",
    "    return input_txt \n",
    "\n",
    "detail = remove_pattern(detail,\"@[\\w]*\")\n",
    "detail = detail.replace('\\n', '')\n",
    "exclude = set(string.punctuation)\n",
    "detail = ''.join(char for char in detail if char not in exclude)\n",
    "\n",
    "stemmer = PorterStemmer() \n",
    "Detail = []\n",
    "for word in detail.split():\n",
    "    Detail.append(stemmer.stem(word))\n",
    "detail = [' '.join(Detail)]\n",
    "detail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0], dtype=int64)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 0 = negative 4  = positive\n",
    "predict = pipeline.predict(detail)\n",
    "predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0], dtype=int64)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
